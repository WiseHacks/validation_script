{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized validation class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        # self.st = time.time()\n",
    "        # for i in range(10):\n",
    "            # self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.now = time.time()        \n",
    "        # print(len(self.gdf), self.now - self.st)\n",
    "        self.NUM_THREADS = 4\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        self.gdf_batches = [self.gdf[i:len(self.gdf) if i == self.NUM_THREADS-1 else i+batch_size] for i in range(0, len(self.gdf), batch_size)]\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date', 'json']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc \n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    def parallel_execution(self, function, *args):\n",
    "        threads = []\n",
    "        results = [True]*self.NUM_THREADS\n",
    "\n",
    "        def worker(*args):\n",
    "            results[args[0]] = function(*args)\n",
    "\n",
    "        for i in range(self.NUM_THREADS):\n",
    "            thread = threading.Thread(target=worker, args=(i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for all threads to finish\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        return all(results)\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(dtype == 'json'):\n",
    "                        continue\n",
    "                    if(shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        raise ValueError(f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}')\n",
    "    \n",
    "    # TODO rows where it is failing\n",
    "    def check_json_structure(self, val):\n",
    "        try:\n",
    "            json.loads(val)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def json_structure_validation(self, thread_id, featurename):\n",
    "        if(self.gdf_batches[thread_id][featurename].apply(self.check_json_structure).all() == False):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def json_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            if 'json' in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes']['json']:\n",
    "                    if(self.parallel_execution(self.json_structure_validation, featurename)==False):\n",
    "                        raise ValueError(f'Invalid json found in feature - {featurename}')\n",
    "\n",
    "    def inclusive_range_validation(self, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] < lower) | (self.gdf_batches[thread_id][featurename] > upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def exclusive_range_validation(self, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] >= lower) & (self.gdf_batches[thread_id][featurename] <= upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in inclusive, we parallelly execute validator function \n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    if(self.parallel_execution(self.inclusive_range_validation, featurename) == False):\n",
    "                        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value outside [{lower},{upper}] found')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in exclusive, we parallelly execute validator function \n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    if(self.parallel_execution(self.exclusive_range_validation, featurename) == False):\n",
    "                        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value found in range [{lower}, {upper}]')\n",
    "\n",
    "    def equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] != val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def not_equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] == val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    if(self.parallel_execution(self.equal_value_validation, featurename) == False):\n",
    "                        val = self.config['attributes']['values']['equal'][featurename]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value found not equal to {val}')\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    if(self.parallel_execution(self.not_equal_value_validation, featurename) == False):\n",
    "                        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value found equal to {val}')\n",
    "\n",
    "    def inclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        # print(self.gdf_batches[thread_id][featurename])\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (~self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "        \n",
    "    def exclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    if(self.parallel_execution(self.inclusive_subset_validation, featurename) == False):\n",
    "                        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value found which does not belong to the {vals}')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    if(self.parallel_execution(self.exclusive_subset_validation, featurename) == False):\n",
    "                        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "                        raise ValueError(f'Invalid value for {featurename}, value found which belongs to the {vals}')\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                if self.gdf[featurename].isnull().any():\n",
    "                    raise ValueError(f'Invalid value for {featurename}, null value found')\n",
    "    \n",
    "    def create_function(self, code):\n",
    "        func_dict = {}\n",
    "        exec(code, globals(), func_dict)\n",
    "        return func_dict['fun']\n",
    "\n",
    "    def run_attributes_check_functions_validation(self, thread_id, featurename):\n",
    "        funcs = self.config['attributes']['check_functions'][featurename]\n",
    "        for func in funcs:\n",
    "            if(self.gdf_batches[thread_id][featurename].apply(self.create_function(func)).all() == False):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            for featurename in config['attributes']['check_functions'].keys():\n",
    "                if(self.parallel_execution(self.run_attributes_check_functions_validation, featurename) == False):\n",
    "                    raise ValueError(f'Invalid value for {featurename} - A function failed')\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                raise ValueError(f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    raise ValueError(f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def run_geometry_check_functions_validation(self, thread_id, featurename = 'geometry'):\n",
    "        funcs = self.config['attributes']['check_functions']\n",
    "        for func in funcs:\n",
    "            if(self.gdf_batches[thread_id][featurename].apply(self.create_function(func)).all() == False):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            if(self.parallel_execution(self.run_geometry_check_functions_validation) == False):\n",
    "                raise ValueError(f'Invalid value for geometry - A function failed')\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # json validation,\n",
    "        self.json_validation()\n",
    "        # ranges validation,\n",
    "        # self.ranges_validation()\n",
    "        # # values validation,\n",
    "        # self.values_validation()\n",
    "        # # subsets validation, (considered for only belonging condition)\n",
    "        # self.subsets_validation()\n",
    "        # # not_null validation,\n",
    "        # self.not_null_validation()\n",
    "        # # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        # self.attributes_check_functions_validation()\n",
    "        \n",
    "        # #### GEOMETRY VALIDATION ####\n",
    "        # # crs validation,\n",
    "        # self.crs_validation()\n",
    "        # # types validation\n",
    "        # self.geometry_types_validation()\n",
    "        # # check_functions validation\n",
    "        # self.geometry_check_function_validation()\n",
    "        print('end', time.time() - self.now)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-9109 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-9107 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Thread-9108 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py:1415: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  result = super().__getitem__(key)\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "Exception in thread Thread-9106 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "Exception in thread Thread-9110 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-9113 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-9111 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "Exception in thread Thread-9112 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "Exception in thread Thread-9114 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-9115 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "Exception in thread Thread-9116 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "Exception in thread Thread-9117 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 43, in worker\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/3537868350.py\", line 92, in json_structure_validation\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/geopandas/geodataframe.py\", line 1415, in __getitem__\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    result = super().__getitem__(key)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3798, in __getitem__\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n",
      "    return self._getitem_bool_array(key)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py\", line 3851, in _getitem_bool_array\n",
      "    key = check_bool_indexer(self.index, key)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/indexing.py\", line 2552, in check_bool_indexer\n",
      "    raise IndexingError(\n",
      "pandas.errors.IndexingError: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end 0.040538787841796875\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int64' : ['Division'],\n",
    "            'text' : ['FeatureNam', 'FeatureSta', 'Condition', 'Visible', 'Legible', 'Reflective',\n",
    "                      'images', 'bboxes', 'geohash', 'fpath', 'RouteName', 'StreetName', 'UUID', \n",
    "                      'RouteMaint', 'RouteID', 'BeginFeatu', 'EndFeature', 'MaintCnt', 'LocCntyC', \n",
    "                      'RouteCla', 'RouteInv', 'Direction', 'TravelDir', 'UniqueID', 'SyncID'],\n",
    "            'float' : ['lat', 'lon', 'MPLength', 'Length', 'Width', 'Area', 'BeginMp1', 'EndMp1',\n",
    "                       'MaxMp1', 'Shape_Leng'],\n",
    "            'json' : ['bboxes', 'images', 'Length']\n",
    "        },\n",
    "        'ranges' : {\n",
    "            'inclusive' : {\n",
    "                'lat' : [0, 100],\n",
    "                'lon' : [-100, 100],\n",
    "                'Division' : [0, 100],\n",
    "                'Length' : [0, 10000],\n",
    "                'Width' : [0, 10000],\n",
    "                'BeginMp1' : [0, 10000],\n",
    "                'EndMp1' : [0, 10000],\n",
    "                'MaxMp1' : [0, 10000],\n",
    "                'MPLength' : [0, 10000],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'lat' : [100, 100],\n",
    "                'lon' : [100, 100],\n",
    "                'Division' : [100, 100],\n",
    "                'Length' : [10000, 10000],\n",
    "                'Width' : [10000, 10000],\n",
    "                'BeginMp1' : [10000, 10000],\n",
    "                'EndMp1' : [10000, 10000],\n",
    "                'MaxMp1' : [10000, 10000],\n",
    "                'MPLength' : [10000, 10000],\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'RouteMaint' : 'System'\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'FeatureNam' : '-1',\n",
    "                'FeatureSta' : '-1', \n",
    "                'Condition' : '-1', \n",
    "                'Visible' : '-1', \n",
    "                'Legible' : '-1', \n",
    "                'Reflective' : '-1',\n",
    "                'images' : '-1',\n",
    "                'bboxes' : '-1', \n",
    "                'geohash' : '-1', \n",
    "                'fpath' : '-1', \n",
    "                'RouteName' : '-1', \n",
    "                'StreetName' : '-1', \n",
    "                'UUID' : '-1', \n",
    "                'RouteMaint' : '-1', \n",
    "                'RouteID' : '-1', \n",
    "                'BeginFeatu' : '-1', \n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            'inclusive' : {\n",
    "                'Condition' : ['good', 'damaged'],\n",
    "                'Visible' : ['0', '1'],\n",
    "                'Legible' : ['0', '1'],\n",
    "                'Reflective' : ['0', '1'],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'FeatureNam' : ['a', 'b'],\n",
    "                'FeatureSta' : ['a', 'b'], \n",
    "                'Condition' : ['a', 'b'], \n",
    "                'Visible' : ['a', 'b'], \n",
    "                'Legible' : ['a', 'b'], \n",
    "                'Reflective' : ['a', 'b'],\n",
    "                'images' : ['a', 'b'],\n",
    "                'bboxes' : ['a', 'b'], \n",
    "                'geohash' : ['a', 'b'], \n",
    "                'fpath' : ['a', 'b'], \n",
    "                'RouteName' : ['a', 'b'], \n",
    "                'StreetName' : ['a', 'b'], \n",
    "                'UUID' : ['a', 'b'], \n",
    "                'RouteMaint' : ['a', 'b'], \n",
    "                'RouteID' : ['a', 'b'], \n",
    "                'BeginFeatu' : ['a', 'b'], \n",
    "                'EndFeature' : ['a', 'b'], \n",
    "                'MaintCnt' : ['a', 'b'], \n",
    "                'LocCntyC' : ['a', 'b'], \n",
    "                'RouteCla' : ['a', 'b'], \n",
    "                'RouteInv' : ['a', 'b'], \n",
    "                'Direction' : ['a', 'b'], \n",
    "                'TravelDir' : ['a', 'b'], \n",
    "                'UniqueID' : ['a', 'b'], \n",
    "                'SyncID' : ['a', 'b'],\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['lat', 'lon', 'images', 'bboxes', 'geohash', 'fpath', 'Length', 'Width', 'Area'], #much more\n",
    "        'check_functions' : {\n",
    "            'lat' : [\n",
    "                    '''def fun(val):\n",
    "                        return val >= 0 and val <= 100\n",
    "                    ''',\n",
    "                    # '''def fun(val):\n",
    "                    #     return val < 35\n",
    "                    # '''\n",
    "                    ]\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        'types' : ['Point']\n",
    "    }\n",
    "}\n",
    "validator = ConfigValidator(config=config, shapefile='../shapefile/point.shp')\n",
    "validator.validate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2\n",
    "#### num_threads as argument now and parallellism on featurenames list..\n",
    "\n",
    "#### changes on version 1 - num_threads as argument, and included validation helper function to achieve parallellism on featurenames list i.e. concurrently apply validation on featurenames in chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        self.st = time.time()\n",
    "        for i in range(12):\n",
    "            self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.now = time.time()        \n",
    "        print(len(self.gdf), self.now - self.st)\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc \n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    def parallel_execution(self, num_threads, function, *args):\n",
    "        threads = []\n",
    "        for i in range(num_threads):\n",
    "            thread = threading.Thread(target=function, args=(num_threads, i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for all threads to finish\n",
    "        try:\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "        except:\n",
    "            for thread in threads:\n",
    "                thread._stop()\n",
    "             \n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        raise ValueError(f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}')\n",
    "\n",
    "    # this is to achieve parallellism in list featurenames.. run for batches parallelly.. \n",
    "    def validation_helper(self, num_threads, thread_id, function, featurenames):\n",
    "        batch_size = len(featurenames)//num_threads\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(featurenames), l + batch_size) - 1\n",
    "        # 7, 4 - 1,1,1,4 \n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(featurenames) - 1 \n",
    "        for ind in range(l, r + 1):\n",
    "            featurename = featurenames[ind]\n",
    "            function(1, 0, featurename)\n",
    "            # self.parallel_execution(1, function, featurename)\n",
    "        pass\n",
    "\n",
    "    def inclusive_range_validation(self, num_threads, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & ((self.gdf[featurename] < lower) | (self.gdf[featurename] > upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value outside [{lower}, {upper}] found')\n",
    "\n",
    "    def exclusive_range_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & ((self.gdf[featurename] >= lower) & (self.gdf[featurename] <= upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found in range [{lower}, {upper}]')\n",
    "\n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.inclusive_range_validation,\n",
    "                    list(config['attributes']['ranges']['inclusive'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.exclusive_range_validation,\n",
    "                    list(config['attributes']['ranges']['exclusive'].keys())\n",
    "                    )\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    self.parallel_execution(1, self.exclusive_range_validation, featurename)\n",
    "\n",
    "    def equal_value_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename] != val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found not equal to {val}')\n",
    "\n",
    "    def not_equal_value_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename] == val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found equal to {val}')\n",
    "    \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.equal_value_validation,\n",
    "                    list(config['attributes']['values']['equal'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.not_equal_value_validation,\n",
    "                    list(config['attributes']['values']['not_equal'].keys())\n",
    "                    )\n",
    "    \n",
    "    def inclusive_subset_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (~self.gdf[featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found which does not belong to the {vals}')\n",
    "        \n",
    "    def exclusive_subset_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found which belongs to the {vals}')\n",
    "\n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.inclusive_subset_validation,\n",
    "                    list(config['attributes']['subsets']['inclusive'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.exclusive_subset_validation,\n",
    "                    list(config['attributes']['subsets']['exclusive'].keys())\n",
    "                    )\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                if self.gdf[featurename].isnull().any():\n",
    "                    raise ValueError(f'Invalid value for {featurename}, null value found')\n",
    "\n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            pass\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                raise ValueError(f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    raise ValueError(f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "            \n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            pass\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "        \n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        print('end', time.time() - self.now)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 - no threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        self.st = time.time()\n",
    "        for i in range(12):\n",
    "            self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.now = time.time()\n",
    "        print(len(self.gdf), self.now - self.st)\n",
    "        self.NUM_THREADS = 1\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config:\n",
    "            raise ValueError(\n",
    "                'Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float',\n",
    "                           'double', 'text', 'objectID', 'date']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(\n",
    "                        f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc\n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    def parallel_execution(self, function, *args):\n",
    "        threads = []\n",
    "        for i in range(self.NUM_THREADS):\n",
    "            thread = threading.Thread(target=function, args=(i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for all threads to finish\n",
    "        try:\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "        except:\n",
    "            for thread in threads:\n",
    "                thread._stop()\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int': np.dtype('int'),\n",
    "                'int64': np.dtype('int64'),\n",
    "                'float': np.dtype('float'),\n",
    "                'float64': np.dtype('float64'),\n",
    "                'double': np.dtype('float'),\n",
    "                'text': np.dtype('object_'),\n",
    "                'objectID': np.dtype('object_'),\n",
    "                'date': np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if (shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        raise ValueError(\n",
    "                            f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}')\n",
    "\n",
    "    def inclusive_range_validation(self, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & ((self.gdf[featurename] < lower) | (self.gdf[featurename] > upper))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value outside [{lower}, {upper}] found')\n",
    "\n",
    "    def exclusive_range_validation(self, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] >= lower) & (self.gdf[featurename] <= upper)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found in range [{lower}, {upper}]')\n",
    "\n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in inclusive, we parallelly execute validator function\n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.inclusive_range_validation, featurename)\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in exclusive, we parallelly execute validator function\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.exclusive_range_validation, featurename)\n",
    "\n",
    "    def equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] != val)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found not equal to {val}')\n",
    "\n",
    "    def not_equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] == val)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found equal to {val}')\n",
    "\n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.equal_value_validation, featurename)\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.not_equal_value_validation, featurename)\n",
    "\n",
    "    def inclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (~self.gdf[featurename].isin(vals) & (self.gdf[featurename] != None))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found which does not belong to the {vals}')\n",
    "\n",
    "    def exclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename].isin(vals))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found which belongs to the {vals}')\n",
    "\n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.inclusive_subset_validation, featurename)\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.exclusive_subset_validation, featurename)\n",
    "\n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                if self.gdf[featurename].isnull().any():\n",
    "                    raise ValueError(\n",
    "                        f'Invalid value for {featurename}, null value found')\n",
    "\n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            pass\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if (str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                raise ValueError(f'Invalid crs {str(self.gdf.crs)} found')\n",
    "\n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    raise ValueError(\n",
    "                        f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            pass\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "\n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        print('end', time.time() - self.now)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "#### Experiment 1\n",
    "Time taken is expected to be higher than we got as reading a shapefile in geopandas may take time\n",
    "\n",
    "// bigger config - \n",
    "\n",
    "version, num of rows, additional time to increase rows, end - total time taken for validation \n",
    "\n",
    "V1 - 7225344 1.3997633457183838\n",
    "end 19.2275447845459 \n",
    "\n",
    "V2 - 7225344 1.4392359256744385\n",
    "end 25.137534856796265\n",
    "\n",
    "V3 - 7225344 1.1619951725006104\n",
    "end 17.309794902801514\n",
    "#### Experiment 2\n",
    "//smaller config - \n",
    "\n",
    "V3 - 28901376 8.447794914245605\n",
    "end 24.983617067337036\n",
    "\n",
    "V2 - 28901376 8.805611848831177\n",
    "end 49.451152324676514\n",
    "\n",
    "V1 - 28901376 8.536412954330444\n",
    "end 36.259761095047\n",
    "#### Experiment 3\n",
    "//bigger config -\n",
    "\n",
    "V3 - 28901376 8.579703092575073\n",
    "end 88.4816601276397\n",
    "\n",
    "V2 - 4 minutes\n",
    "\n",
    "V1 - 95 sec\n",
    "#### Experiment 4\n",
    "//bigger\n",
    "\n",
    "V3 - 3612672 0.56266188621521\n",
    "end 8.773582220077515\n",
    "\n",
    "V2 - 3612672 0.560664176940918\n",
    "end 10.410000085830688\n",
    "\n",
    "V1 - 3612672 0.5555088520050049\n",
    "end 9.491483211517334\n",
    "#### Experiment 5\n",
    "//smaller\n",
    "\n",
    "V3 - 3612672 0.5471899509429932\n",
    "end 2.008450031280517\n",
    "\n",
    "V2 - 3612672 0.5653510093688965\n",
    "end 2.100717067718506\n",
    "\n",
    "V1 - 3612672 0.5493388175964355\n",
    "end 2.0935730934143066\n",
    "\n",
    "#### Version 4 is a mix of v2 and v3, v3 is small optimisation of v1, only v3 is complete (json structure validation remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General validation config for a shapefile \n",
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int' : ['featurename'],\n",
    "            'int64' : [],\n",
    "            'float' : [],\n",
    "            'float64' : [],\n",
    "            'double' : [],\n",
    "            'text' : [],\n",
    "            'objectID' : [],\n",
    "            'date' : []\n",
    "        },\n",
    "        'ranges' : {\n",
    "            # all values\n",
    "            'inclusive' : {\n",
    "                'featurename' : ['lower', 'uppper'], #lower <= val <= upper\n",
    "                # ...\n",
    "                # can have mulitple ranges\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'featurename' : ['lower', 'upper'], #val < lower, val > upper\n",
    "                # ...\n",
    "                # can have multiple ranges\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'featurename' : 'val', \n",
    "                # ...\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'featurename' : 'val', \n",
    "                # ...\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            # all values\n",
    "            'inclusive' : {\n",
    "                'featurename' : ['values'],\n",
    "                # ...\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'featurename' : ['values'],\n",
    "                # ...\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['features which must not have null, missing values'],\n",
    "        # 'null' : ['features which can be null'],\n",
    "        # custom functions for complex checks like, for town = oldtown, all featurestatus should be active, something like that\n",
    "        'check_functions' : {\n",
    "            'featurename' : ['function definitions in python maybe']\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        # there will be only one column for geometry, which can be of type point, polygon, etc\n",
    "        'crs' : '',\n",
    "        'types' : ['Point'],\n",
    "        'check_functions' : []\n",
    "        # it depends, maybe area, distance, intersection pairwise, number of overlaps, it can be anything\n",
    "        # which is passed as functions, so will it be a good idea? \n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

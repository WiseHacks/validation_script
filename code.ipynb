{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized validation class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "from geopandas import pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        self.report = 'report_sc.txt'\n",
    "        self.validation_success_status = True\n",
    "        # self.st = time.time()\n",
    "        # for i in range(10):\n",
    "            # self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.start_time = time.time()        \n",
    "        # print(len(self.gdf), self.now - self.st)\n",
    "        self.gdf = self.gdf[0:10]\n",
    "        self.NUM_THREADS = 4\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        self.gdf_batches = [self.gdf[i:len(self.gdf) if i//batch_size == self.NUM_THREADS-1 else i+batch_size] for i in range(0, len(self.gdf), batch_size)]\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date', 'json']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc \n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    # function is the validation function which must return two things,\n",
    "    # bool, filtered dataframe which would be used to generate the report\n",
    "    def parallel_execution(self, function, *args):\n",
    "        threads = []\n",
    "        results = [None]*self.NUM_THREADS\n",
    "\n",
    "        def worker(*args):\n",
    "            results[args[0]] = function(*args)\n",
    "\n",
    "        for i in range(self.NUM_THREADS):\n",
    "            thread = threading.Thread(target=worker, args=(i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for the threads\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        verdicts = []\n",
    "        invalid_dfs = []\n",
    "        for verdict, invalid_df in results:\n",
    "            verdicts.append(verdict)\n",
    "            invalid_dfs.append(invalid_df)\n",
    "\n",
    "        return all(verdicts), pd.concat(invalid_dfs)\n",
    "\n",
    "    def update_report(self, df, msg):\n",
    "        with open(self.report, 'a') as f:\n",
    "            f.writelines(f'Message - {msg}\\n\\n\\n')\n",
    "            if(df is not None):\n",
    "                np.savetxt(f, df.values, fmt='%s', delimiter='\\t')\n",
    "                f.writelines('\\n\\n\\n')\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(dtype == 'json'):\n",
    "                        continue\n",
    "                    if(shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(None, f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}\\n\\n\\n')\n",
    "    \n",
    "    def check_json_structure(self, val):\n",
    "        try:\n",
    "            json.loads(val)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def json_structure_validation(self, thread_id, featurename):\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].apply(self.check_json_structure) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def json_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            if 'json' in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes']['json']:\n",
    "                    verdict, invalid_df = self.parallel_execution(self.json_structure_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df, f'JSON validation failed - Invalid json found in feature - {featurename} In the following rows')\n",
    "\n",
    "    def inclusive_range_validation(self, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] < lower) | (self.gdf_batches[thread_id][featurename] > upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def exclusive_range_validation(self, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] >= lower) & (self.gdf_batches[thread_id][featurename] <= upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.inclusive_range_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df, f'Inclusive ranges validation failed - Invalid value for {featurename}, value outside [{lower},{upper}] found in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.exclusive_range_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df, f'Exclusive ranges validation failed - Invalid value for {featurename}, value found in range [{lower}, {upper}] found in the following rows')\n",
    "\n",
    "    def equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] != val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def not_equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] == val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.equal_value_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['equal'][featurename]\n",
    "                        self.update_report(invalid_df, f'Equal value validation failed - Invalid value for {featurename}, value found not equal to {val} in the following rows')\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.not_equal_value_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "                        self.update_report(invalid_df, f'Non-Equal value validation failed - Invalid value for {featurename}, value found equal to {val} in the following rows')\n",
    "\n",
    "    def inclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        # print(self.gdf_batches[thread_id][featurename])\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (~self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def exclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.inclusive_subset_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "                        self.update_report(invalid_df, f'Inclusive subsets validation failed - Invalid value for {featurename}, value found which does not belong to the {vals} in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.exclusive_subset_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "                        self.update_report(invalid_df, f'Exclusive subsets validation failed - Invalid value for {featurename}, value found which belongs to the {vals} in the following rows')\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                filtered_gdf = self.gdf[self.gdf[featurename].isnull()]\n",
    "                if(len(filtered_gdf) > 0):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(filtered_gdf, f'Null check validation failed - Invalid value for {featurename}, null value found in the following rows')\n",
    "    \n",
    "    def create_function(self, code):\n",
    "        func_dict = {}\n",
    "        exec(code, globals(), func_dict)\n",
    "        return func_dict['fun']\n",
    "\n",
    "    def run_check_functions_validation(self, thread_id, featurename, func):\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].apply(self.create_function(func)) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            for featurename in config['attributes']['check_functions'].keys():\n",
    "                funcs = config['attributes']['check_functions'][featurename]\n",
    "                for func in funcs:\n",
    "                    verdict, invalid_df = self.parallel_execution(self.run_check_functions_validation, featurename, func)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df, f'Function check failed - Invalid value for {featurename} - A function check {func} failed in the following rows')\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                self.validation_success_status = False\n",
    "                self.update_report(None, f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(None, f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            funcs = config['geometry']['check_functions']\n",
    "            for func in funcs:\n",
    "                verdict, invalid_df = self.parallel_execution(self.run_check_functions_validation, 'geometry', func)\n",
    "                if(verdict == False):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(invalid_df, f'Function check failed - Invalid value for geometry - A function check {func} failed in the following rows')\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # json validation,\n",
    "        self.json_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "        \n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        time_taken = time.time() - self.start_time\n",
    "        if(self.validation_success_status == True):\n",
    "            self.update_report(None, f'Validation successful')\n",
    "        self.update_report(None, f'time taken for whole process: {time_taken}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int64' : ['Division'],\n",
    "            'text' : ['FeatureNam', 'FeatureSta', 'Condition', 'Visible', 'Legible', 'Reflective',\n",
    "                      'images', 'bboxes', 'geohash', 'fpath', 'RouteName', 'StreetName', 'UUID', \n",
    "                      'RouteMaint', 'RouteID', 'BeginFeatu', 'EndFeature', 'MaintCnt', 'LocCntyC', \n",
    "                      'RouteCla', 'RouteInv', 'Direction', 'TravelDir', 'UniqueID', 'SyncID'],\n",
    "            'float' : ['lat', 'lon', 'MPLength', 'Length', 'Width', 'Area', 'BeginMp1', 'EndMp1',\n",
    "                       'MaxMp1', 'Shape_Leng'],\n",
    "            'json' : ['bboxes', 'images']\n",
    "        },\n",
    "        'ranges' : {\n",
    "            'inclusive' : {\n",
    "                'lat' : [0, 100],\n",
    "                'lon' : [-100, 100],\n",
    "                'Division' : [0, 100],\n",
    "                'Length' : [0, 10000],\n",
    "                'Width' : [0, 10000],\n",
    "                'BeginMp1' : [0, 10000],\n",
    "                'EndMp1' : [0, 10000],\n",
    "                'MaxMp1' : [0, 10000],\n",
    "                'MPLength' : [0, 10000],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'lat' : [100, 100],\n",
    "                'lon' : [100, 100],\n",
    "                'Division' : [100, 100],\n",
    "                'Length' : [10000, 10000],\n",
    "                'Width' : [10000, 10000],\n",
    "                'BeginMp1' : [10000, 10000],\n",
    "                'EndMp1' : [10000, 10000],\n",
    "                'MaxMp1' : [10000, 10000],\n",
    "                'MPLength' : [10000, 10000],\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'RouteMaint' : 'System'\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'FeatureNam' : '-1',\n",
    "                'FeatureSta' : '-1', \n",
    "                'Condition' : '-1', \n",
    "                'Visible' : '-1', \n",
    "                'Legible' : '-1', \n",
    "                'Reflective' : '-1',\n",
    "                'images' : '-1',\n",
    "                'bboxes' : '-1', \n",
    "                'geohash' : '-1', \n",
    "                'fpath' : '-1', \n",
    "                'RouteName' : '-1', \n",
    "                'StreetName' : '-1', \n",
    "                'UUID' : '-1', \n",
    "                'RouteMaint' : '-1', \n",
    "                'RouteID' : '-1', \n",
    "                'BeginFeatu' : '-1', \n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            'inclusive' : {\n",
    "                'Condition' : ['good', 'damaged'],\n",
    "                'Visible' : ['0', '1'],\n",
    "                'Legible' : ['0', '1'],\n",
    "                'Reflective' : ['0', '1'],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'FeatureNam' : ['a', 'b'],\n",
    "                'FeatureSta' : ['a', 'b'], \n",
    "                'Condition' : ['a', 'b'], \n",
    "                'Visible' : ['a', 'b'], \n",
    "                'Legible' : ['a', 'b'], \n",
    "                'Reflective' : ['a', 'b'],\n",
    "                'images' : ['a', 'b'],\n",
    "                'bboxes' : ['a', 'b'], \n",
    "                'geohash' : ['a', 'b'], \n",
    "                'fpath' : ['a', 'b'], \n",
    "                'RouteName' : ['a', 'b'], \n",
    "                'StreetName' : ['a', 'b'], \n",
    "                'UUID' : ['a', 'b'], \n",
    "                'RouteMaint' : ['a', 'b'], \n",
    "                'RouteID' : ['a', 'b'], \n",
    "                'BeginFeatu' : ['a', 'b'], \n",
    "                'EndFeature' : ['a', 'b'], \n",
    "                'MaintCnt' : ['a', 'b'], \n",
    "                'LocCntyC' : ['a', 'b'], \n",
    "                'RouteCla' : ['a', 'b'], \n",
    "                'RouteInv' : ['a', 'b'], \n",
    "                'Direction' : ['a', 'b'], \n",
    "                'TravelDir' : ['a', 'b'], \n",
    "                'UniqueID' : ['a', 'b'], \n",
    "                'SyncID' : ['a', 'b'],\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['lat', 'lon', 'images', 'bboxes', 'geohash', 'fpath', 'Length', 'Width', 'Area'], #much more\n",
    "        'check_functions' : {\n",
    "            'lat' : [\n",
    "                    '''def fun(val):\n",
    "                        return val >= 0 and val <= 100\n",
    "                    ''',\n",
    "                    # '''def fun(val):\n",
    "                    #     return val < 35\n",
    "                    # '''\n",
    "                    ]\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        'types' : ['Point']\n",
    "    }\n",
    "}\n",
    "validator = ConfigValidator(config=config, shapefile='../shapefile/point.shp')\n",
    "validator.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-10967 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-10968 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Exception in thread Thread-10969 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "Thread-10966 (worker):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 49, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 49, in worker\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 49, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 49, in worker\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 244, in run_check_functions_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 244, in run_check_functions_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 244, in run_check_functions_validation\n",
      "  File \"/var/folders/sn/qh3j97250m7btdtc25ptm51h0000gq/T/ipykernel_79792/493413128.py\", line 244, in run_check_functions_validation\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py\", line 4771, in apply\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py\", line 4771, in apply\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py\", line 4771, in apply\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/series.py\", line 4771, in apply\n",
      "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1123, in apply\n",
      "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1123, in apply\n",
      "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1123, in apply\n",
      "    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1123, in apply\n",
      "    return self.apply_standard()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1174, in apply_standard\n",
      "    return self.apply_standard()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1174, in apply_standard\n",
      "    return self.apply_standard()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1174, in apply_standard\n",
      "    return self.apply_standard()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/lib/python3.11/site-packages/pandas/core/apply.py\", line 1174, in apply_standard\n",
      "    mapped = lib.map_infer(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/lib.pyx\", line 2924, in pandas._libs.lib.map_infer\n",
      "    mapped = lib.map_infer(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/lib.pyx\", line 2924, in pandas._libs.lib.map_infer\n",
      "    mapped = lib.map_infer(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/lib.pyx\", line 2924, in pandas._libs.lib.map_infer\n",
      "    mapped = lib.map_infer(\n",
      "             ^^^^^^^^^^^^^^\n",
      "  File \"pandas/_libs/lib.pyx\", line 2924, in pandas._libs.lib.map_infer\n",
      "  File \"<string>\", line 3, in fun\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py\", line 339, in loads\n",
      "  File \"<string>\", line 3, in fun\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py\", line 339, in loads\n",
      "  File \"<string>\", line 3, in fun\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py\", line 339, in loads\n",
      "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not float\n",
      "  File \"<string>\", line 3, in fun\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.2_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py\", line 339, in loads\n",
      "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not float\n",
      "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not float\n",
      "    raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n",
      "TypeError: the JSON object must be str, bytes or bytearray, not float\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[271], line 135\u001b[0m\n\u001b[1;32m      1\u001b[0m config \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mattributes\u001b[39m\u001b[39m'\u001b[39m : {\n\u001b[1;32m      3\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdtypes\u001b[39m\u001b[39m'\u001b[39m : {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     }\n\u001b[1;32m    133\u001b[0m }\n\u001b[1;32m    134\u001b[0m validator \u001b[39m=\u001b[39m ConfigValidator(config\u001b[39m=\u001b[39mconfig, shapefile\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../shapefile/point.shp\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m validator\u001b[39m.\u001b[39;49mvalidate()\n",
      "Cell \u001b[0;32mIn[270], line 302\u001b[0m, in \u001b[0;36mConfigValidator.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_null_validation()\n\u001b[1;32m    301\u001b[0m \u001b[39m# check_functions validation, (run function for all values in feature, all must be true)\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattributes_check_functions_validation()\n\u001b[1;32m    304\u001b[0m \u001b[39m#### GEOMETRY VALIDATION ####\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# crs validation,\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcrs_validation()\n",
      "Cell \u001b[0;32mIn[270], line 253\u001b[0m, in \u001b[0;36mConfigValidator.attributes_check_functions_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m funcs \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mattributes\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcheck_functions\u001b[39m\u001b[39m'\u001b[39m][featurename]\n\u001b[1;32m    252\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 253\u001b[0m     verdict, invalid_df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_execution(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_check_functions_validation, featurename, func)\n\u001b[1;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m(verdict \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    255\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidation_success_status \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[270], line 65\u001b[0m, in \u001b[0;36mConfigValidator.parallel_execution\u001b[0;34m(self, function, *args)\u001b[0m\n\u001b[1;32m     63\u001b[0m verdicts \u001b[39m=\u001b[39m []\n\u001b[1;32m     64\u001b[0m invalid_dfs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 65\u001b[0m \u001b[39mfor\u001b[39;00m verdict, invalid_df \u001b[39min\u001b[39;00m results:\n\u001b[1;32m     66\u001b[0m     verdicts\u001b[39m.\u001b[39mappend(verdict)\n\u001b[1;32m     67\u001b[0m     invalid_dfs\u001b[39m.\u001b[39mappend(invalid_df)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int64' : ['Division'],\n",
    "            'text' : ['FeatureNam', 'FeatureSta', 'Condition', 'Visible', 'Legible', 'Reflective',\n",
    "                      'images', 'bboxes', 'geohash', 'fpath', 'RouteName', 'StreetName', 'UUID', \n",
    "                      'RouteMaint', 'RouteID', 'BeginFeatu', 'EndFeature', 'MaintCnt', 'LocCntyC', \n",
    "                      'RouteCla', 'RouteInv', 'Direction', 'TravelDir', 'UniqueID', 'SyncID', 'lat'],\n",
    "            'float' : ['lat', 'lon', 'MPLength', 'Length', 'Width', 'Area', 'BeginMp1', 'EndMp1',\n",
    "                       'MaxMp1', 'Shape_Leng', 'FeatureNam'],\n",
    "            'json' : ['images', 'bboxes', 'Length']\n",
    "        },\n",
    "        'ranges' : {\n",
    "            'inclusive' : {\n",
    "                'lat' : [0, 0],\n",
    "                'lon' : [-100, 100],\n",
    "                'Division' : [0, 100],\n",
    "                'Length' : [0, 10000],\n",
    "                'Width' : [0, 10000],\n",
    "                'BeginMp1' : [0, 10000],\n",
    "                'EndMp1' : [0, 10000],\n",
    "                'MaxMp1' : [0, 10000],\n",
    "                'MPLength' : [0, 10000],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'lat' : [0, 100],\n",
    "                'lon' : [100, 100],\n",
    "                'Division' : [100, 100],\n",
    "                'Length' : [10000, 10000],\n",
    "                'Width' : [10000, 10000],\n",
    "                'BeginMp1' : [10000, 10000],\n",
    "                'EndMp1' : [10000, 10000],\n",
    "                'MaxMp1' : [10000, 10000],\n",
    "                'MPLength' : [10000, 10000],\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'RouteMaint' : '-1'\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'FeatureNam' : '-1',\n",
    "                'FeatureSta' : '-1', \n",
    "                'Condition' : '-1', \n",
    "                'Visible' : '-1', \n",
    "                'Legible' : '-1', \n",
    "                'Reflective' : '-1',\n",
    "                'images' : '-1',\n",
    "                'bboxes' : '-1', \n",
    "                'geohash' : '-1', \n",
    "                'fpath' : '-1', \n",
    "                'RouteName' : '-1', \n",
    "                'StreetName' : '-1', \n",
    "                'UUID' : '-1', \n",
    "                'RouteMaint' : 'System', \n",
    "                'RouteID' : '-1', \n",
    "                'BeginFeatu' : '-1', \n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            'inclusive' : {\n",
    "                'Condition' : ['good'],\n",
    "                'Visible' : ['0', '1'],\n",
    "                'Legible' : ['0', '1'],\n",
    "                'Reflective' : ['0', '1'],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'FeatureNam' : ['a', 'b'],\n",
    "                'FeatureSta' : ['a', 'b'], \n",
    "                'Condition' : ['a', 'b', 'good'], \n",
    "                'Visible' : ['a', 'b'], \n",
    "                'Legible' : ['a', 'b'], \n",
    "                'Reflective' : ['a', 'b'],\n",
    "                'images' : ['a', 'b'],\n",
    "                'bboxes' : ['a', 'b'], \n",
    "                'geohash' : ['a', 'b'], \n",
    "                'fpath' : ['a', 'b'], \n",
    "                'RouteName' : ['a', 'b'], \n",
    "                'StreetName' : ['a', 'b'], \n",
    "                'UUID' : ['a', 'b'], \n",
    "                'RouteMaint' : ['a', 'b', 'System'], \n",
    "                'RouteID' : ['a', 'b'], \n",
    "                'BeginFeatu' : ['a', 'b'], \n",
    "                'EndFeature' : ['a', 'b'], \n",
    "                'MaintCnt' : ['a', 'b'], \n",
    "                'LocCntyC' : ['a', 'b'], \n",
    "                'RouteCla' : ['a', 'b'], \n",
    "                'RouteInv' : ['a', 'b'], \n",
    "                'Direction' : ['a', 'b'], \n",
    "                'TravelDir' : ['a', 'b'], \n",
    "                'UniqueID' : ['a', 'b'], \n",
    "                'SyncID' : ['a', 'b'],\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['lat', 'lon', 'images', 'bboxes', 'geohash', 'fpath', 'Length', 'Width', 'Area', 'Condition'], #much more\n",
    "        'check_functions' : {\n",
    "            'lat' : [\n",
    "                    '''def fun(val):\n",
    "                        return val >= 0 and val <= 100\n",
    "                    ''',\n",
    "                    # '''def fun(val):\n",
    "                    #     return val < 35\n",
    "                    # '''\n",
    "                    '''def fun(val):\n",
    "                        import json\n",
    "                        x = json.loads(val)\n",
    "                        return len(x['bbox']) == 1\n",
    "                    ''',\n",
    "                    ]\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        'types' : ['Polygon']\n",
    "    }\n",
    "}\n",
    "validator = ConfigValidator(config=config, shapefile='../shapefile/point.shp')\n",
    "validator.validate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2\n",
    "#### num_threads as argument now and parallellism on featurenames list..\n",
    "\n",
    "#### changes on version 1 - num_threads as argument, and included validation helper function to achieve parallellism on featurenames list i.e. concurrently apply validation on featurenames in chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        self.st = time.time()\n",
    "        for i in range(12):\n",
    "            self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.now = time.time()        \n",
    "        print(len(self.gdf), self.now - self.st)\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc \n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    def parallel_execution(self, num_threads, function, *args):\n",
    "        threads = []\n",
    "        for i in range(num_threads):\n",
    "            thread = threading.Thread(target=function, args=(num_threads, i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for all threads to finish\n",
    "        try:\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "        except:\n",
    "            for thread in threads:\n",
    "                thread._stop()\n",
    "             \n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        raise ValueError(f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}')\n",
    "\n",
    "    # this is to achieve parallellism in list featurenames.. run for batches parallelly.. \n",
    "    def validation_helper(self, num_threads, thread_id, function, featurenames):\n",
    "        batch_size = len(featurenames)//num_threads\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(featurenames), l + batch_size) - 1\n",
    "        # 7, 4 - 1,1,1,4 \n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(featurenames) - 1 \n",
    "        for ind in range(l, r + 1):\n",
    "            featurename = featurenames[ind]\n",
    "            function(1, 0, featurename)\n",
    "            # self.parallel_execution(1, function, featurename)\n",
    "        pass\n",
    "\n",
    "    def inclusive_range_validation(self, num_threads, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & ((self.gdf[featurename] < lower) | (self.gdf[featurename] > upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value outside [{lower}, {upper}] found')\n",
    "\n",
    "    def exclusive_range_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & ((self.gdf[featurename] >= lower) & (self.gdf[featurename] <= upper))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found in range [{lower}, {upper}]')\n",
    "\n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.inclusive_range_validation,\n",
    "                    list(config['attributes']['ranges']['inclusive'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.exclusive_range_validation,\n",
    "                    list(config['attributes']['ranges']['exclusive'].keys())\n",
    "                    )\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    self.parallel_execution(1, self.exclusive_range_validation, featurename)\n",
    "\n",
    "    def equal_value_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename] != val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found not equal to {val}')\n",
    "\n",
    "    def not_equal_value_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename] == val)]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found equal to {val}')\n",
    "    \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.equal_value_validation,\n",
    "                    list(config['attributes']['values']['equal'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.not_equal_value_validation,\n",
    "                    list(config['attributes']['values']['not_equal'].keys())\n",
    "                    )\n",
    "    \n",
    "    def inclusive_subset_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (~self.gdf[featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found which does not belong to the {vals}')\n",
    "        \n",
    "    def exclusive_subset_validation(self, num_threads, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//num_threads\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if(thread_id == num_threads - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (self.gdf[featurename].notnull()) & (self.gdf[featurename].isin(vals))]\n",
    "        if(len(filtered_gdf) > 0):\n",
    "            raise ValueError(f'Invalid value for {featurename}, value found which belongs to the {vals}')\n",
    "\n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.inclusive_subset_validation,\n",
    "                    list(config['attributes']['subsets']['inclusive'].keys())\n",
    "                    )\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                self.parallel_execution(\n",
    "                    4,\n",
    "                    self.validation_helper,\n",
    "                    self.exclusive_subset_validation,\n",
    "                    list(config['attributes']['subsets']['exclusive'].keys())\n",
    "                    )\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                if self.gdf[featurename].isnull().any():\n",
    "                    raise ValueError(f'Invalid value for {featurename}, null value found')\n",
    "\n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            pass\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                raise ValueError(f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    raise ValueError(f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "            \n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            pass\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "        \n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        print('end', time.time() - self.now)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1 - no threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, shapefile):\n",
    "        self.config = config\n",
    "        self.shapefile = shapefile\n",
    "        self.gdf = geopandas.read_file(shapefile)\n",
    "        self.st = time.time()\n",
    "        for i in range(12):\n",
    "            self.gdf = self.gdf.append(self.gdf)\n",
    "        # for i in range(4):\n",
    "        #     self.gdf = self.gdf.append(self.gdf)\n",
    "        # self.gdf = self.gdf.append(self.gdf)\n",
    "        self.now = time.time()\n",
    "        print(len(self.gdf), self.now - self.st)\n",
    "        self.NUM_THREADS = 1\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config:\n",
    "            raise ValueError(\n",
    "                'Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float',\n",
    "                           'double', 'text', 'objectID', 'date']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(\n",
    "                        f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc\n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    def parallel_execution(self, function, *args):\n",
    "        threads = []\n",
    "        for i in range(self.NUM_THREADS):\n",
    "            thread = threading.Thread(target=function, args=(i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for all threads to finish\n",
    "        try:\n",
    "            for thread in threads:\n",
    "                thread.join()\n",
    "        except:\n",
    "            for thread in threads:\n",
    "                thread._stop()\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            shapefile_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int': np.dtype('int'),\n",
    "                'int64': np.dtype('int64'),\n",
    "                'float': np.dtype('float'),\n",
    "                'float64': np.dtype('float64'),\n",
    "                'double': np.dtype('float'),\n",
    "                'text': np.dtype('object_'),\n",
    "                'objectID': np.dtype('object_'),\n",
    "                'date': np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if (shapefile_dtypes[featurename] != mp[dtype]):\n",
    "                        raise ValueError(\n",
    "                            f'Invalid data type for {featurename}, should be {mp[dtype]} but is {shapefile_dtypes[featurename]}')\n",
    "\n",
    "    def inclusive_range_validation(self, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & ((self.gdf[featurename] < lower) | (self.gdf[featurename] > upper))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value outside [{lower}, {upper}] found')\n",
    "\n",
    "    def exclusive_range_validation(self, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] >= lower) & (self.gdf[featurename] <= upper)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found in range [{lower}, {upper}]')\n",
    "\n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in inclusive, we parallelly execute validator function\n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.inclusive_range_validation, featurename)\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "                # for all featurename in exclusive, we parallelly execute validator function\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.exclusive_range_validation, featurename)\n",
    "\n",
    "    def equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] != val)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found not equal to {val}')\n",
    "\n",
    "    def not_equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename] == val)]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found equal to {val}')\n",
    "\n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.equal_value_validation, featurename)\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.not_equal_value_validation, featurename)\n",
    "\n",
    "    def inclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (~self.gdf[featurename].isin(vals) & (self.gdf[featurename] != None))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found which does not belong to the {vals}')\n",
    "\n",
    "    def exclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        # gdf = self.gdf\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        # thread_id represents l to r in gdf\n",
    "        l = thread_id * batch_size\n",
    "        r = min(len(self.gdf), l + batch_size) - 1\n",
    "        if (thread_id == self.NUM_THREADS - 1):\n",
    "            r = len(self.gdf) - 1\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        filtered_gdf = self.gdf[(self.gdf.index >= l) & (self.gdf.index <= r) & (\n",
    "            self.gdf[featurename].notnull()) & (self.gdf[featurename].isin(vals))]\n",
    "        if (len(filtered_gdf) > 0):\n",
    "            raise ValueError(\n",
    "                f'Invalid value for {featurename}, value found which belongs to the {vals}')\n",
    "\n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.inclusive_subset_validation, featurename)\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    self.parallel_execution(\n",
    "                        self.exclusive_subset_validation, featurename)\n",
    "\n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                if self.gdf[featurename].isnull().any():\n",
    "                    raise ValueError(\n",
    "                        f'Invalid value for {featurename}, null value found')\n",
    "\n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            pass\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if (str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                raise ValueError(f'Invalid crs {str(self.gdf.crs)} found')\n",
    "\n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    raise ValueError(\n",
    "                        f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            pass\n",
    "\n",
    "    def validate(self):\n",
    "        self.validate_config_structure()\n",
    "        #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "\n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        print('end', time.time() - self.now)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "#### Experiment 1\n",
    "Time taken is expected to be higher than we got as reading a shapefile in geopandas may take time\n",
    "\n",
    "// bigger config - \n",
    "\n",
    "version, num of rows, additional time to increase rows, end - total time taken for validation \n",
    "\n",
    "V1 - 7225344 1.3997633457183838\n",
    "end 19.2275447845459 \n",
    "\n",
    "V2 - 7225344 1.4392359256744385\n",
    "end 25.137534856796265\n",
    "\n",
    "V3 - 7225344 1.1619951725006104\n",
    "end 17.309794902801514\n",
    "#### Experiment 2\n",
    "//smaller config - \n",
    "\n",
    "V3 - 28901376 8.447794914245605\n",
    "end 24.983617067337036\n",
    "\n",
    "V2 - 28901376 8.805611848831177\n",
    "end 49.451152324676514\n",
    "\n",
    "V1 - 28901376 8.536412954330444\n",
    "end 36.259761095047\n",
    "#### Experiment 3\n",
    "//bigger config -\n",
    "\n",
    "V3 - 28901376 8.579703092575073\n",
    "end 88.4816601276397\n",
    "\n",
    "V2 - 4 minutes\n",
    "\n",
    "V1 - 95 sec\n",
    "#### Experiment 4\n",
    "//bigger\n",
    "\n",
    "V3 - 3612672 0.56266188621521\n",
    "end 8.773582220077515\n",
    "\n",
    "V2 - 3612672 0.560664176940918\n",
    "end 10.410000085830688\n",
    "\n",
    "V1 - 3612672 0.5555088520050049\n",
    "end 9.491483211517334\n",
    "#### Experiment 5\n",
    "//smaller\n",
    "\n",
    "V3 - 3612672 0.5471899509429932\n",
    "end 2.008450031280517\n",
    "\n",
    "V2 - 3612672 0.5653510093688965\n",
    "end 2.100717067718506\n",
    "\n",
    "V1 - 3612672 0.5493388175964355\n",
    "end 2.0935730934143066\n",
    "\n",
    "#### Version 4 is a mix of v2 and v3, v3 is small optimisation of v1, only v3 is complete (json structure validation remains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General validation config for a shapefile \n",
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int' : ['featurename'],\n",
    "            'int64' : [],\n",
    "            'float' : [],\n",
    "            'float64' : [],\n",
    "            'double' : [],\n",
    "            'text' : [],\n",
    "            'objectID' : [],\n",
    "            'date' : []\n",
    "        },\n",
    "        'ranges' : {\n",
    "            # all values\n",
    "            'inclusive' : {\n",
    "                'featurename' : ['lower', 'uppper'], #lower <= val <= upper\n",
    "                # ...\n",
    "                # can have mulitple ranges\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'featurename' : ['lower', 'upper'], #val < lower, val > upper\n",
    "                # ...\n",
    "                # can have multiple ranges\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'featurename' : 'val', \n",
    "                # ...\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'featurename' : 'val', \n",
    "                # ...\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            # all values\n",
    "            'inclusive' : {\n",
    "                'featurename' : ['values'],\n",
    "                # ...\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'featurename' : ['values'],\n",
    "                # ...\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['features which must not have null, missing values'],\n",
    "        # 'null' : ['features which can be null'],\n",
    "        # custom functions for complex checks like, for town = oldtown, all featurestatus should be active, something like that\n",
    "        'check_functions' : {\n",
    "            'featurename' : ['function definitions in python maybe']\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        # there will be only one column for geometry, which can be of type point, polygon, etc\n",
    "        'crs' : '',\n",
    "        'types' : ['Point'],\n",
    "        'check_functions' : []\n",
    "        # it depends, maybe area, distance, intersection pairwise, number of overlaps, it can be anything\n",
    "        # which is passed as functions, so will it be a good idea? \n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

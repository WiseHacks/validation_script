{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import dask_geopandas as gdd\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, input_file, report_path):\n",
    "        self.start_time = time.time()\n",
    "        self.config = config\n",
    "        self.input_file = input_file\n",
    "        self.gdf = gdd.read_file(input_file, npartitions = 4)\n",
    "        # self.gdf = self.gdf.compute()\n",
    "        print(len(self.gdf))\n",
    "        self.report = report_path\n",
    "        self.validation_success_status = True\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date', 'json']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "\n",
    "    def update_report(self, df_vals, msg):\n",
    "        with open(self.report, 'a') as f:\n",
    "            f.writelines(f'Message - {msg}\\n\\n\\n')\n",
    "            if(df_vals is not None):\n",
    "                np.savetxt(f, df_vals, fmt='%s', delimiter='\\t')\n",
    "                f.writelines('\\n\\n\\n')\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # read shapefile in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            input_file_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(dtype == 'json'):\n",
    "                        continue\n",
    "                    if(input_file_dtypes[featurename] != mp[dtype]):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(None, f'Invalid data type for {featurename}, should be {mp[dtype]} but is {input_file_dtypes[featurename]}\\n\\n\\n')\n",
    "    \n",
    "    def check_json_structure(self, val):\n",
    "        try:\n",
    "            json.loads(val)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def json_structure_validation(self, featurename):\n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].apply(self.check_json_structure, meta=(featurename, 'bool')) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def json_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            if 'json' in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes']['json']:\n",
    "                    verdict, invalid_df = self.json_structure_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df.values.compute(), f'JSON validation failed - Invalid json found in feature - {featurename} In the following rows')\n",
    "\n",
    "    def inclusive_range_validation(self, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "\n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & ((self.gdf[featurename] < lower) | (self.gdf[featurename] > upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def exclusive_range_validation(self, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        \n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & ((self.gdf[featurename] >= lower) & (self.gdf[featurename] <= upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.inclusive_range_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Inclusive ranges validation failed - Invalid value for {featurename}, value outside [{lower},{upper}] found in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.exclusive_range_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Exclusive ranges validation failed - Invalid value for {featurename}, value found in range [{lower}, {upper}] found in the following rows')\n",
    "\n",
    "    def equal_value_validation(self, featurename):\n",
    "        # all_vals = val\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & (self.gdf[featurename] != val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def not_equal_value_validation(self, featurename):\n",
    "        # all_vals != val\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & (self.gdf[featurename] == val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    verdict, invalid_df = self.equal_value_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['equal'][featurename]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Equal value validation failed - Invalid value for {featurename}, value found not equal to {val} in the following rows')\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    verdict, invalid_df = self.not_equal_value_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Non-Equal value validation failed - Invalid value for {featurename}, value found equal to {val} in the following rows')\n",
    "\n",
    "    def inclusive_subset_validation(self, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        # print(self.gdf[featurename])\n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & (~self.gdf[featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def exclusive_subset_validation(self, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].notnull()) & (self.gdf[featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.inclusive_subset_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Inclusive subsets validation failed - Invalid value for {featurename}, value found which does not belong to the {vals} in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.exclusive_subset_validation(featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "                        self.update_report(invalid_df.values.compute(), f'Exclusive subsets validation failed - Invalid value for {featurename}, value found which belongs to the {vals} in the following rows')\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                filtered_gdf = self.gdf[self.gdf[featurename].isnull()]\n",
    "                if(len(filtered_gdf) > 0):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(filtered_gdf.values.compute(), f'Null check validation failed - Invalid value for {featurename}, null value found in the following rows')\n",
    "    \n",
    "    def create_function(self, code):\n",
    "        func_dict = {}\n",
    "        exec(code, globals(), func_dict)\n",
    "        return func_dict['fun']\n",
    "\n",
    "    def run_check_functions_validation(self, featurename, func):\n",
    "        filtered_gdf = self.gdf[(self.gdf[featurename].apply(self.create_function(func), meta=(featurename, 'bool')) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            for featurename in config['attributes']['check_functions'].keys():\n",
    "                funcs = config['attributes']['check_functions'][featurename]\n",
    "                for func in funcs:\n",
    "                    verdict, invalid_df = self.run_check_functions_validation(featurename, func)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df.values.compute(), f'Function check failed - Invalid value for {featurename} - A function check {func} failed in the following rows')\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                self.validation_success_status = False\n",
    "                self.update_report(None, f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(None, f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            funcs = config['geometry']['check_functions']\n",
    "            for func in funcs:\n",
    "                verdict, invalid_df = self.run_check_functions_validation('geometry', func)\n",
    "                if(verdict == False):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(invalid_df.values.compute(), f'Function check failed - Invalid value for geometry - A function check {func} failed in the following rows')\n",
    "\n",
    "    def validate(self):\n",
    "        # self.validate_config_structure()\n",
    "        # #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # json validation,\n",
    "        self.json_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "        \n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        time_taken = time.time() - self.start_time\n",
    "        if(self.validation_success_status == True):\n",
    "            self.update_report(None, f'Validation successful')\n",
    "        self.update_report(None, f'time taken for whole process: {time_taken}')\n",
    "        print('Time :', time_taken)\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903168\n",
      "Time : 35.86536979675293\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'attributes' : {\n",
    "        'dtypes' : {\n",
    "            'int64' : ['Division'],\n",
    "            'text' : ['FeatureNam', 'FeatureSta', 'Condition', 'Visible', 'Legible', 'Reflective',\n",
    "                      'images', 'bboxes', 'geohash', 'fpath', 'RouteName', 'StreetName', 'UUID', \n",
    "                      'RouteMaint', 'RouteID', 'BeginFeatu', 'EndFeature', 'MaintCnt', 'LocCntyC', \n",
    "                      'RouteCla', 'RouteInv', 'Direction', 'TravelDir', 'UniqueID', 'SyncID'],\n",
    "            'float' : ['lat', 'lon', 'MPLength', 'Length', 'Width', 'Area', 'BeginMp1', 'EndMp1',\n",
    "                       'MaxMp1', 'Shape_Leng'],\n",
    "            'json' : ['bboxes', 'images']\n",
    "        },\n",
    "        'ranges' : {\n",
    "            'inclusive' : {\n",
    "                'lat' : [0, 100],\n",
    "                'lon' : [-100, 100],\n",
    "                'Division' : [0, 100],\n",
    "                'Length' : [0, 10000],\n",
    "                'Width' : [0, 10000],\n",
    "                'BeginMp1' : [0, 10000],\n",
    "                'EndMp1' : [0, 10000],\n",
    "                'MaxMp1' : [0, 10000],\n",
    "                'MPLength' : [0, 10000],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'lat' : [100, 100],\n",
    "                'lon' : [100, 100],\n",
    "                'Division' : [100, 100],\n",
    "                'Length' : [10000, 10000],\n",
    "                'Width' : [10000, 10000],\n",
    "                'BeginMp1' : [10000, 10000],\n",
    "                'EndMp1' : [10000, 10000],\n",
    "                'MaxMp1' : [10000, 10000],\n",
    "                'MPLength' : [10000, 10000],\n",
    "            }\n",
    "        },\n",
    "        'values' : {\n",
    "            'equal' : {\n",
    "                'RouteMaint' : 'System'\n",
    "            },\n",
    "            'not_equal' : {\n",
    "                'FeatureNam' : '-1',\n",
    "                'FeatureSta' : '-1', \n",
    "                'Condition' : '-1', \n",
    "                'Visible' : '-1', \n",
    "                'Legible' : '-1', \n",
    "                'Reflective' : '-1',\n",
    "                'images' : '-1',\n",
    "                'bboxes' : '-1', \n",
    "                'geohash' : '-1', \n",
    "                'fpath' : '-1', \n",
    "                'RouteName' : '-1', \n",
    "                'StreetName' : '-1', \n",
    "                'UUID' : '-1', \n",
    "                'RouteMaint' : '-1', \n",
    "                'RouteID' : '-1', \n",
    "                'BeginFeatu' : '-1', \n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "                'EndFeature' : '-1', \n",
    "                'MaintCnt' : '-1', \n",
    "                'LocCntyC' : '-1', \n",
    "                'RouteCla' : '-1', \n",
    "                'RouteInv' : '-1', \n",
    "                'Direction' : '-1', \n",
    "                'TravelDir' : '-1', \n",
    "                'UniqueID' : '-1', \n",
    "                'SyncID' : '-1',\n",
    "            }\n",
    "        },\n",
    "        'subsets' : {\n",
    "            'inclusive' : {\n",
    "                'Condition' : ['good', 'damaged'],\n",
    "                'Visible' : ['0', '1'],\n",
    "                'Legible' : ['0', '1'],\n",
    "                'Reflective' : ['0', '1'],\n",
    "            },\n",
    "            'exclusive' : {\n",
    "                'FeatureNam' : ['a', 'b'],\n",
    "                'FeatureSta' : ['a', 'b'], \n",
    "                'Condition' : ['a', 'b'], \n",
    "                'Visible' : ['a', 'b'], \n",
    "                'Legible' : ['a', 'b'], \n",
    "                'Reflective' : ['a', 'b'],\n",
    "                'images' : ['a', 'b'],\n",
    "                'bboxes' : ['a', 'b'], \n",
    "                'geohash' : ['a', 'b'], \n",
    "                'fpath' : ['a', 'b'], \n",
    "                'RouteName' : ['a', 'b'], \n",
    "                'StreetName' : ['a', 'b'], \n",
    "                'UUID' : ['a', 'b'], \n",
    "                'RouteMaint' : ['a', 'b'], \n",
    "                'RouteID' : ['a', 'b'], \n",
    "                'BeginFeatu' : ['a', 'b'], \n",
    "                'EndFeature' : ['a', 'b'], \n",
    "                'MaintCnt' : ['a', 'b'], \n",
    "                'LocCntyC' : ['a', 'b'], \n",
    "                'RouteCla' : ['a', 'b'], \n",
    "                'RouteInv' : ['a', 'b'], \n",
    "                'Direction' : ['a', 'b'], \n",
    "                'TravelDir' : ['a', 'b'], \n",
    "                'UniqueID' : ['a', 'b'], \n",
    "                'SyncID' : ['a', 'b'],\n",
    "            }\n",
    "        },\n",
    "        'not_null' : ['lat', 'lon', 'images', 'bboxes', 'geohash', 'fpath', 'Length', 'Width', 'Area'], #much more\n",
    "        'check_functions' : {\n",
    "            'lat' : [\n",
    "                    '''def fun(val):\n",
    "                        return val >= 0 and val <= 100\n",
    "                    ''',\n",
    "                    # '''def fun(val):\n",
    "                    #     return val < 35\n",
    "                    # '''\n",
    "                    ]\n",
    "        }\n",
    "    },\n",
    "    'geometry' : {\n",
    "        'types' : ['Point']\n",
    "    }\n",
    "}\n",
    "validator = ConfigValidator(config, '../shapefile_/point_.shp', 'report.txt')\n",
    "validator.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopandas import pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "import dask_geopandas as gdd\n",
    "\n",
    "class ConfigValidator:\n",
    "    def __init__(self, config, input_file, report_path):\n",
    "        self.start_time = time.time()        \n",
    "        self.config = config\n",
    "        self.input_file = input_file\n",
    "        self.NUM_THREADS = 4\n",
    "        self.gdf = gdd.read_file(input_file, npartitions=self.NUM_THREADS).compute()\n",
    "        self.report = report_path\n",
    "        self.validation_success_status = True\n",
    "        print(len(self.gdf))\n",
    "        batch_size = len(self.gdf)//self.NUM_THREADS\n",
    "        self.gdf_batches = [self.gdf[i:len(self.gdf) if i//batch_size == self.NUM_THREADS-1 else i+batch_size] for i in range(0, len(self.gdf), batch_size)]\n",
    "\n",
    "    def validate_config_structure(self):\n",
    "        config = self.config\n",
    "        if 'attributes' not in config: \n",
    "            raise ValueError('Invalid Config - Property \"attributes\" not found')\n",
    "        if 'geometry' not in config:\n",
    "            raise ValueError('Invalid Config - Property \"geometry\" not found')\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            valid_types = ['int', 'int64', 'float', 'double', 'text', 'objectID', 'date', 'json']\n",
    "            for key in config['attributes']['dtypes'].keys():\n",
    "                if key not in valid_types:\n",
    "                    raise ValueError(f'Invalid Config - invalid dtype - \"{key}\"')\n",
    "        # we can have more validations on this, like valid functions, valid featurename lists etc \n",
    "        # not needed as config will be generated from template or stored\n",
    "\n",
    "    # function is the validation function which must return two things,\n",
    "    # bool, filtered dataframe which would be used to generate the report\n",
    "    def parallel_execution(self, function, *args):\n",
    "        threads = []\n",
    "        results = [None]*self.NUM_THREADS\n",
    "\n",
    "        def worker(*args):\n",
    "            results[args[0]] = function(*args)\n",
    "\n",
    "        for i in range(self.NUM_THREADS):\n",
    "            thread = threading.Thread(target=worker, args=(i,) + args)\n",
    "            threads.append(thread)\n",
    "\n",
    "        # start the threads\n",
    "        for thread in threads:\n",
    "            thread.start()\n",
    "\n",
    "        # wait for the threads\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "        verdicts = []\n",
    "        invalid_dfs = []\n",
    "        for verdict, invalid_df in results:\n",
    "            verdicts.append(verdict)\n",
    "            invalid_dfs.append(invalid_df)\n",
    "\n",
    "        return all(verdicts), pd.concat(invalid_dfs)\n",
    "\n",
    "    def update_report(self, df, msg):\n",
    "        with open(self.report, 'a') as f:\n",
    "            f.writelines(f'Message - {msg}\\n\\n\\n')\n",
    "            if(df is not None):\n",
    "                np.savetxt(f, df.values, fmt='%s', delimiter='\\t')\n",
    "                f.writelines('\\n\\n\\n')\n",
    "\n",
    "    def dtypes_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            # gdf = self.gdf\n",
    "            # read input_file in geopandas - dtype in pandas - object, int64, float64, datetime64, bool\n",
    "            input_file_dtypes = self.gdf.dtypes\n",
    "            # mp to map standard types to pandas types\n",
    "            mp = {\n",
    "                'int' : np.dtype('int'),\n",
    "                'int64' : np.dtype('int64'),\n",
    "                'float' : np.dtype('float'),\n",
    "                'float64' : np.dtype('float64'),\n",
    "                'double' : np.dtype('float'),\n",
    "                'text' : np.dtype('object_'),\n",
    "                'objectID' : np.dtype('object_'),\n",
    "                'date' : np.dtype('datetime64')\n",
    "            }\n",
    "            for dtype in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes'][dtype]:\n",
    "                    if(dtype == 'json'):\n",
    "                        continue\n",
    "                    if(input_file_dtypes[featurename] != mp[dtype]):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(None, f'Invalid data type for {featurename}, should be {mp[dtype]} but is {input_file_dtypes[featurename]}\\n\\n\\n')\n",
    "    \n",
    "    def check_json_structure(self, val):\n",
    "        try:\n",
    "            json.loads(val)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def json_structure_validation(self, thread_id, featurename):\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].apply(self.check_json_structure) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def json_validation(self):\n",
    "        config = self.config\n",
    "        if 'dtypes' in config['attributes']:\n",
    "            if 'json' in config['attributes']['dtypes']:\n",
    "                for featurename in config['attributes']['dtypes']['json']:\n",
    "                    verdict, invalid_df = self.parallel_execution(self.json_structure_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df, f'JSON validation failed - Invalid json found in feature - {featurename} In the following rows')\n",
    "\n",
    "    def inclusive_range_validation(self, thread_id, featurename):\n",
    "        # lower <= all_vals <= upper \n",
    "        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] < lower) | (self.gdf_batches[thread_id][featurename] > upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def exclusive_range_validation(self, thread_id, featurename):\n",
    "        # all_vals < lower or all_vals > upper \n",
    "        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "        lower, upper = bounds[0], bounds[1]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & ((self.gdf_batches[thread_id][featurename] >= lower) & (self.gdf_batches[thread_id][featurename] <= upper))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def ranges_validation(self):\n",
    "        config = self.config\n",
    "        if 'ranges' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.inclusive_range_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['inclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df, f'Inclusive ranges validation failed - Invalid value for {featurename}, value outside [{lower},{upper}] found in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['ranges']:\n",
    "\n",
    "                for featurename in config['attributes']['ranges']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.exclusive_range_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        bounds = self.config['attributes']['ranges']['exclusive'][featurename]\n",
    "                        lower, upper = bounds[0], bounds[1]\n",
    "                        self.update_report(invalid_df, f'Exclusive ranges validation failed - Invalid value for {featurename}, value found in range [{lower}, {upper}] found in the following rows')\n",
    "\n",
    "    def equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals = val\n",
    "        val = self.config['attributes']['values']['equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] != val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "\n",
    "    def not_equal_value_validation(self, thread_id, featurename):\n",
    "        # all_vals != val\n",
    "        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename] == val)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def values_validation(self):\n",
    "        config = self.config\n",
    "        if 'values' in config['attributes']:\n",
    "            if 'equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['equal'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.equal_value_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['equal'][featurename]\n",
    "                        self.update_report(invalid_df, f'Equal value validation failed - Invalid value for {featurename}, value found not equal to {val} in the following rows')\n",
    "\n",
    "            if 'not_equal' in config['attributes']['values']:\n",
    "                for featurename in config['attributes']['values']['not_equal'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.not_equal_value_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        val = self.config['attributes']['values']['not_equal'][featurename]\n",
    "                        self.update_report(invalid_df, f'Non-Equal value validation failed - Invalid value for {featurename}, value found equal to {val} in the following rows')\n",
    "\n",
    "    def inclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "        # print(self.gdf_batches[thread_id][featurename])\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (~self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "        \n",
    "    def exclusive_subset_validation(self, thread_id, featurename):\n",
    "        # all_vals not belongs to vals\n",
    "        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "        \n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].notnull()) & (self.gdf_batches[thread_id][featurename].isin(vals))]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def subsets_validation(self):\n",
    "        config = self.config\n",
    "        if 'subsets' in config['attributes']:\n",
    "            if 'inclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['inclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.inclusive_subset_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['inclusive'][featurename]\n",
    "                        self.update_report(invalid_df, f'Inclusive subsets validation failed - Invalid value for {featurename}, value found which does not belong to the {vals} in the following rows')\n",
    "\n",
    "            if 'exclusive' in config['attributes']['subsets']:\n",
    "                for featurename in config['attributes']['subsets']['exclusive'].keys():\n",
    "                    verdict, invalid_df = self.parallel_execution(self.exclusive_subset_validation, featurename)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        vals = self.config['attributes']['subsets']['exclusive'][featurename]\n",
    "                        self.update_report(invalid_df, f'Exclusive subsets validation failed - Invalid value for {featurename}, value found which belongs to the {vals} in the following rows')\n",
    "        \n",
    "    def not_null_validation(self):\n",
    "        config = self.config\n",
    "        if 'not_null' in config['attributes']:\n",
    "            for featurename in config['attributes']['not_null']:\n",
    "                filtered_gdf = self.gdf[self.gdf[featurename].isnull()]\n",
    "                if(len(filtered_gdf) > 0):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(filtered_gdf, f'Null check validation failed - Invalid value for {featurename}, null value found in the following rows')\n",
    "    \n",
    "    def create_function(self, code):\n",
    "        func_dict = {}\n",
    "        exec(code, globals(), func_dict)\n",
    "        return func_dict['fun']\n",
    "\n",
    "    def run_check_functions_validation(self, thread_id, featurename, func):\n",
    "        filtered_gdf = self.gdf_batches[thread_id][(self.gdf_batches[thread_id][featurename].apply(self.create_function(func)) == False)]\n",
    "        return len(filtered_gdf) == 0, filtered_gdf\n",
    "    \n",
    "    def attributes_check_functions_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['attributes']:\n",
    "            for featurename in config['attributes']['check_functions'].keys():\n",
    "                funcs = config['attributes']['check_functions'][featurename]\n",
    "                for func in funcs:\n",
    "                    verdict, invalid_df = self.parallel_execution(self.run_check_functions_validation, featurename, func)\n",
    "                    if(verdict == False):\n",
    "                        self.validation_success_status = False\n",
    "                        self.update_report(invalid_df, f'Function check failed - Invalid value for {featurename} - A function check {func} failed in the following rows')\n",
    "\n",
    "    def crs_validation(self):\n",
    "        config = self.config\n",
    "        if 'crs' in config['geometry']:\n",
    "            if(str(self.gdf.crs) != config['geometry']['crs']):\n",
    "                self.validation_success_status = False\n",
    "                self.update_report(None, f'Invalid crs {str(self.gdf.crs)} found')\n",
    "            \n",
    "    def geometry_types_validation(self):\n",
    "        config = self.config\n",
    "        # workaround for now...\n",
    "        if 'types' in config['geometry']:\n",
    "            valid_types = config['geometry']['types']\n",
    "            types_found = set(self.gdf.geom_type)\n",
    "            for type in types_found:\n",
    "                if type not in valid_types:\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(None, f'Invalid geometry type {type} found, it should be from {valid_types}')\n",
    "\n",
    "    def geometry_check_function_validation(self):\n",
    "        config = self.config\n",
    "        if 'check_functions' in config['geometry']:\n",
    "            funcs = config['geometry']['check_functions']\n",
    "            for func in funcs:\n",
    "                verdict, invalid_df = self.parallel_execution(self.run_check_functions_validation, 'geometry', func)\n",
    "                if(verdict == False):\n",
    "                    self.validation_success_status = False\n",
    "                    self.update_report(invalid_df, f'Function check failed - Invalid value for geometry - A function check {func} failed in the following rows')\n",
    "\n",
    "    def validate(self):\n",
    "        # self.validate_config_structure()\n",
    "        # #### ATTRIBUTES ####\n",
    "        # dtypes validation,\n",
    "        self.dtypes_validation()\n",
    "        # json validation,\n",
    "        self.json_validation()\n",
    "        # ranges validation,\n",
    "        self.ranges_validation()\n",
    "        # values validation,\n",
    "        self.values_validation()\n",
    "        # subsets validation, (considered for only belonging condition)\n",
    "        self.subsets_validation()\n",
    "        # not_null validation,\n",
    "        self.not_null_validation()\n",
    "        # check_functions validation, (run function for all values in feature, all must be true)\n",
    "        self.attributes_check_functions_validation()\n",
    "        \n",
    "        #### GEOMETRY VALIDATION ####\n",
    "        # crs validation,\n",
    "        self.crs_validation()\n",
    "        # types validation\n",
    "        self.geometry_types_validation()\n",
    "        # check_functions validation\n",
    "        self.geometry_check_function_validation()\n",
    "        time_taken = time.time() - self.start_time\n",
    "        if(self.validation_success_status == True):\n",
    "            self.update_report(None, f'Validation successful')\n",
    "        self.update_report(None, f'time taken for whole process: {time_taken}')\n",
    "        print('Time :', time_taken)\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
